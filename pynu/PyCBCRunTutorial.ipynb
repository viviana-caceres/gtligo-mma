{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d99f53-1089-422e-97e1-b6419eb1f3ee",
   "metadata": {},
   "source": [
    "# Running DtDp PDF generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259bd145-9ac7-4441-9672-d9c817aa11cd",
   "metadata": {},
   "source": [
    "Source environment:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5757447-22ac-4049-bbd8-68115093d009",
   "metadata": {},
   "source": [
    "conda activate /home/hannah.griggs/.conda/envs/pynu-dev-23/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f094253d-dfc0-4ab7-a2b8-55ed94703313",
   "metadata": {},
   "source": [
    "Begin with the GPS time and approximate sky error region for the event "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5eddb-54bd-4a4a-a5d5-f30872da978b",
   "metadata": {},
   "source": [
    "Edit region variables in run_dtdphase.sh"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b473c654-cbd3-4175-90a3-f89f1704da4e",
   "metadata": {},
   "source": [
    "ra_min=288.75\n",
    "ra_max=296.25\n",
    "dec_min=-30.0\n",
    "dec_max=-60.0\n",
    "\n",
    "trig_time=1369694512.10\n",
    "\n",
    "event_name=S230601bf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1e077-20fd-4b36-90b1-76ea03b8453a",
   "metadata": {},
   "source": [
    "If no event name from GraceDB, give it a unique identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20998028-6d2f-43fa-82cb-e30a0e1cab31",
   "metadata": {},
   "source": [
    "Run the script:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53df58fe-9ca8-45dd-88e0-d8600467a7f4",
   "metadata": {},
   "source": [
    "./run_dtdphase.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff59bc-bb75-4f59-8c3d-c469d4840eb3",
   "metadata": {},
   "source": [
    "The output should be one L1H1 PDF"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f93c850f-efe3-4413-954a-06e432f6ae10",
   "metadata": {},
   "source": [
    "--output-file ${ifos[0]}${ifos[1]}-stat-${event_name}.hdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37875b2f-8026-4c04-be85-9cacf79fdf30",
   "metadata": {},
   "source": [
    "Keep track of this file's location, you'll have a bunch of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf1ec0-3644-46e2-a65b-d5422db5ecfe",
   "metadata": {},
   "source": [
    "# To start a PyCBC run with your new PDF:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39639915-6abf-4327-9a23-fced1a551986",
   "metadata": {},
   "source": [
    "The O4 environment we're using:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b282584-2a78-4b50-ad44-02e7c41f0b1a",
   "metadata": {},
   "source": [
    "source /cvmfs/oasis.opensciencegrid.org/ligo/sw/pycbc/x86_64_rhel_8/virtualenv/pycbc-v2.1.3/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde0112-76af-4196-90f8-750fd85bc5c4",
   "metadata": {},
   "source": [
    "## Part 1: Reusing matched filtering results from existing analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b2622-fa98-4e39-a2c6-3f6253941f49",
   "metadata": {},
   "source": [
    "This can be tricky. The overarching steps are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc51e49-d1b8-4edf-acf5-f4383c5266cf",
   "metadata": {},
   "source": [
    "1. Find the corresponding offline PyCBC box, it will be in someone's directory according to (for O3) https://wiki.ligo.org/CBC/Searches/PycbcC01HlRunSchedule\n",
    "2. Copy over the reuse.map file from that run directory. In there should be the paths to all of the files that could be reused for another run of PyCBC\n",
    "3. Remove all files post-coinc step. That's a lot of files so you'll need to be careful about this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd74b230-7e3f-4ce0-8e0d-00175b348d2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "So let's break that down. First, open up the file and get ready to delete a bunch of lines. The lines we are removing represent all the output files from the coincident jobs and onward in the workflow. In other words, everything that depends on running pycbc_coinc_findtrigs. \n",
    "\n",
    "Things to keep in mind: \n",
    "- There is a logic to this file. It populates in order of job completion, so it's safe to assume that you want to keep everything before the first \"COINC\" output file shows up.\n",
    "- This file follows the structure of the main.dax files. If you want to double check anything, open up the dax file in the run directory and trace where the output of the coinc jobs go. \n",
    "\n",
    "#### The lines you want to remove are:\n",
    "1. Everything after FIT_OVER_... files until the next set of inspiral jobs start.\n",
    "2. all \"COINC\" \n",
    "3. all \"STATMAP\"\n",
    "4. all injection, range, coincident, followup plotting (\"PLOT\"). Basically all plotting except for the initial plotting that happens before inspiral jobs get started.\n",
    "5. all \"SNGLS COINC\" stuff\n",
    "\n",
    "O4-specifc Plus:\n",
    "1. \"H1L1-EXCLUDE_ZEROLAG_FULL_DATA_2DET\"......hdf\n",
    "2. \"H1L1-FOREGROUND_CENSOR\".......xml\n",
    "3. \"H1L1-HDFINJFIND_NSBHSEOBNRV4_INJ_INJECTIONS\"........hdf\n",
    "4. \"H1L1-HDFINJFIND_ALL_INJECTIONS-1368975466\"........hdf\n",
    "\n",
    "It's possible I'm forgetting something so this may need to be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c597ea6-e72b-49ac-ae6e-fba99d8e4199",
   "metadata": {},
   "source": [
    "#### The next set of files you'll need are here:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30beb0bb-d9ba-494c-8abd-587723f45a3a",
   "metadata": {},
   "source": [
    "/home/hannah.griggs/nu/banks/pynu_tests/skyloc/tests/run_testing/events_test/o4c1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef15dae-007f-490f-92ef-d08dffa9c2b3",
   "metadata": {},
   "source": [
    "In here are ini files for the pycbc workflow. To note here are:\n",
    "1. analysis_dtdp.ini (contains adjusted dtdp pdf input line, you'll want to edit this with your custum pdf)\n",
    "2. c1location (shortcut to original pycbc box, good to keep on hand as you'll be referencing the dax in there)\n",
    "3. run.sh (the run script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8c655-d054-4d37-999f-531ee7ece57b",
   "metadata": {},
   "source": [
    "run.sh will need to be edited as:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a9ec328-2377-4b0c-a2db-f84c2df22acc",
   "metadata": {},
   "source": [
    "WORKFLOW_NAME=mmatest ## you can keep this the same\n",
    "CHUNKNUMBER=1 ## Change to reflect which chunk your event is in\n",
    "CONFIG_TAG=v2.3.2.3 ## Keep this\n",
    "DESCRIPTION='INITIAL_OR_RERUN_OR_SOME_DESCRIPTIVE_WORD' #(NOTE: no spaces, INITIAL recommended for first run)\n",
    "GITLAB_URL=\"https://git.ligo.org/pycbc/offline-analysis/-/raw/${CONFIG_TAG}/prouction/o4/broad/config\"\n",
    "ID=S230601bf_3 ## Change to reflect the unique identifier that goes with the dtdphase PDF you made"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d44d293-cbb7-4592-a257-7f280a02f0fa",
   "metadata": {},
   "source": [
    "kinit hannah.griggs ## Change to your ligo name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5533baf6-70e7-4207-9456-76dbb9b4681a",
   "metadata": {},
   "source": [
    "*** Make sure all the paths are for your directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74968eb5-1e16-4d4a-b264-775fcdcfb832",
   "metadata": {},
   "source": [
    "### For jobs that will use the reuse.map file, such as these ones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8916c00-8407-427c-ad1e-07b796ac690f",
   "metadata": {},
   "source": [
    "Make sure that one of the arguments for pycbc_make_offline_search_workflow is:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1085898-b5a2-4c86-a96e-d3c020329bbd",
   "metadata": {},
   "source": [
    "--cache-file reuse.map \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49225c-11aa-4cfd-8e26-6f2f9fb1df74",
   "metadata": {},
   "source": [
    "### To use O3 data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9020283-efb5-442b-81a3-d94bee8e22c5",
   "metadata": {},
   "source": [
    "Download this file to replace the corresponding \"data\" file in the o4 run.sh file:\n",
    "https://git.ligo.org/ligo-cbc/pycbc-config/-/blob/master/O3C01/pipelineHL/data_O3_C01_clean.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783f2ce-7f28-4a4d-b3f6-28b8aa4ceab5",
   "metadata": {},
   "source": [
    "The GPS times will need to be specified. CHUNKNUMBER corresponds to the GPS time stretch, but we want O3 ones. So, \n",
    "1. Take the start and end GPS times from the O3 boxes page for your chunk\n",
    "2. Edit the gps_times ini file to reflect the new start and end times AND\n",
    "3. Delete the segments-dq-file entry, since O3 didn't use this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39d975e-04b7-4039-88c2-edb85fedfecf",
   "metadata": {},
   "source": [
    "Once that is all in place, you should be good to run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e14e9-44c8-41f6-8be7-854b587aab3e",
   "metadata": {},
   "source": [
    "### To run:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea1d610-14b6-4b32-b7b5-ae62b2e3a635",
   "metadata": {},
   "source": [
    "1. Double check that the paths are correct and that you've sourced the pycbc environment\n",
    "2. Run the workflow generator:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e20e5a3a-faa2-4a69-a45d-a5b893cc97cb",
   "metadata": {},
   "source": [
    "./run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b3d5c-292f-4717-b98e-573783ebb6c5",
   "metadata": {},
   "source": [
    "3. Enter necessary credentials\n",
    "4. Make sure setup completes\n",
    "5. Then it should be running! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c49ef4-8af9-4d75-9d36-234d9d7447b7",
   "metadata": {},
   "source": [
    "You'll need to babysit the jobs since they've been having issues with disk space and memory.\n",
    "Check how the queue is doing from within the run directory with:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9383f2be-0dc9-4bdd-80e9-d38e577fdb52",
   "metadata": {},
   "source": [
    "./status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd78fd15-ad10-47e6-b191-b17d78e2521c",
   "metadata": {},
   "source": [
    "### If jobs are struggling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d31359-1db7-421c-b57e-dbac3d0a2371",
   "metadata": {},
   "source": [
    "1. If jobs are getting held, see the reason with:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b261f6d-c657-4ca1-b86f-984c1d3caf46",
   "metadata": {},
   "source": [
    "condor_q better-analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b49471-b6fe-40b2-bef9-113f257fc46f",
   "metadata": {},
   "source": [
    "This will tell you which job requirements are insufficient and by how much. If memory or disk space are the problem, update held jobs like this:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5e5a00f-2868-44c2-b96f-fbe698966051",
   "metadata": {},
   "source": [
    "condor_qedit -constraint \"JOBSTATUS==5\" RequestDisk=newrequestamount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fee1d6-207c-457c-861c-3eb393d4d85a",
   "metadata": {},
   "source": [
    "Change RequestDisk to RequestMemory as needed, and only request a little over what the jobs seem to need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6afe9f-5cb6-44d7-8450-93d2fbda5995",
   "metadata": {},
   "source": [
    "Release jobs again with "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea6e1124-4eb5-483a-ba19-1180071bae9c",
   "metadata": {},
   "source": [
    "condor_release -constraint \"JOBSTATUS==5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c465c7e-af45-459c-9c66-26a3caa14c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c71b6d51-c6f9-4042-a665-6e725e6c8b1d",
   "metadata": {},
   "source": [
    "This is more straightforward but more intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e11fb4-8367-4591-a5fa-f40fe56ae5f1",
   "metadata": {},
   "source": [
    "Source the working O4 PyCBC environment: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2daf84ce-5f83-4423-9b97-c8d5775d2627",
   "metadata": {},
   "source": [
    "source /cvmfs/software.igwn.org//pycbc/x86_64_rhel_8/virtualenv/pycbc-v2.3.2/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b9cac3-6cfe-42ce-b795-ddcf880f6fe4",
   "metadata": {},
   "source": [
    "1. Identify your GPS time and determine your time range. I usually go with 30,000 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc6b69-0118-4ef4-9da1-923f21e93d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": " igwn-py",
   "language": "python",
   "name": "igwn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
